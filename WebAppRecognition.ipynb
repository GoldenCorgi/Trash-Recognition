{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Output AWS HackDays.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiFAfamTC5qk",
        "colab_type": "text"
      },
      "source": [
        "# Trash Detection using Visual Recognition\n",
        "\n",
        "---- Model - **EfficientNet**  \n",
        "---- Framework - **PyTorch**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVT7wSRguinv",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQXVAa1lVw5D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Installing Libraries { display-mode: \"form\" }\n",
        "\n",
        "!pip install albumentations==0.4.6\n",
        "!pip install efficientnet_pytorch==0.6.3\n",
        "!pip install gradio==1.0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "_8t8CoW4C5qt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Library Imports {display-mode: \"form\"}\n",
        "\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import albumentations as A\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "import gradio as gr\n",
        "from PIL import Image\n",
        "\n",
        "import warnings  \n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Constants\n",
        "IMG_SIZE = 300\n",
        "CATEGORIES = [\"cardboard\",\"glass\",\"metal\",\"paper\",\"plastic\",\"trash\"]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvM4TN-fC5q6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Defining Classes {display-mode: \"form\"}\n",
        "\n",
        "\n",
        "class ID_Dataset(Dataset):\n",
        "    \n",
        "    def __init__(self, df, transforms=None):\n",
        "    \n",
        "        self.df = df\n",
        "        self.transforms=transforms\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.df.shape[0]\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        image_src = self.df.loc[idx, 'full_path']\n",
        "        # print(image_src)\n",
        "        image = cv2.imread(image_src, cv2.IMREAD_COLOR)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        labels = self.df.loc[idx, CATEGORIES].values\n",
        "        labels = torch.from_numpy(labels.astype(np.int8))\n",
        "        labels = labels.unsqueeze(-1)\n",
        "        \n",
        "        if self.transforms:\n",
        "            transformed = self.transforms(image=image)\n",
        "            image = transformed['image']\n",
        "\n",
        "        return image, labels\n",
        "class ID_Model(nn.Module):\n",
        "    \n",
        "    def __init__(self, num_classes=4,initfc_type='normal',gain=0.2):\n",
        "        super().__init__()\n",
        "        model = EfficientNet.from_pretrained('efficientnet-b3')\n",
        "                \n",
        "        self.model = model\n",
        "        self.fc = nn.Linear(model._conv_head.out_channels, num_classes)\n",
        "\n",
        "        if hasattr(self.fc, 'bias') and self.fc.bias is not None:\n",
        "            nn.init.constant_(self.fc.bias.data, 0.0)\n",
        "        if initfc_type == 'normal':\n",
        "            nn.init.normal_(self.fc.weight.data, 0.0, gain)\n",
        "        elif initfc_type == 'xavier':\n",
        "            nn.init.xavier_normal_(self.fc.weight.data, gain=gain)\n",
        "        elif initfc_type == 'kaiming':\n",
        "            nn.init.kaiming_normal_(self.fc.weight.data, a=0, mode='fan_in')\n",
        "        elif initfc_type == 'orthogonal':\n",
        "            nn.init.orthogonal_(self.fc.weight.data, gain=gain)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.model.extract_features(x)\n",
        "        x = x * torch.sigmoid(x)\n",
        "        x = nn.functional.adaptive_avg_pool2d(x, 1).squeeze(-1).squeeze(-1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "temp_df = pd.DataFrame([['temp.jpg',0,0,0,0,0,0]],columns=['full_path']+CATEGORIES)\n",
        "def predictions_gradio(img):\n",
        "    transforms_preds = A.Compose([\n",
        "    A.Resize(height=IMG_SIZE, width=IMG_SIZE, p=1.0),\n",
        "    A.Normalize(p=1.0),\n",
        "    ToTensorV2(p=1.0),\n",
        "])\n",
        "    image = Image.fromarray(img.astype('uint8'), 'RGB')\n",
        "    image.save('temp.jpg')\n",
        "    dataset_test = ID_Dataset(df=temp_df, transforms=transforms_preds)\n",
        "    dataloader_preds = DataLoader(dataset_test, batch_size=1, shuffle=False)\n",
        "\n",
        "    for step, batch in enumerate(dataloader_preds):\n",
        "\n",
        "        images = batch[0]\n",
        "        images = images.to(device, dtype=torch.float)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(images)\n",
        "\n",
        "            test_preds = outputs.data.cpu()\n",
        "\n",
        "\n",
        "    s = ('-----\\n')\n",
        "    d = {}\n",
        "    for idx in torch.topk(outputs, k=6).indices.squeeze(0).tolist():\n",
        "        prob = torch.softmax(outputs, dim=1)[0, idx].item()\n",
        "        s = s + ('{label}{space}({p:.2f}%)\\n'.format(label=CATEGORIES[idx],space=' '*(20-len(CATEGORIES[idx])), p=prob*100))\n",
        "        d[CATEGORIES[idx]] = prob\n",
        "    return s\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrrkBXv4C5rZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Downloading Pretrained Model {display-mode: \"form\"}\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = ID_Model(num_classes=len(CATEGORIES))\n",
        "model.load_state_dict(torch.load('https://raw.githubusercontent.com/GoldenCorgi/AWS-Hackdays/master/model.pth',map_location=device))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "print(\"Model Loading Completed\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6yf80bHC5rr",
        "colab_type": "text"
      },
      "source": [
        "# Running webapp with image editting software"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mnb85ZZ3YL7j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "outputId": "4af5365e-fe85-4b50-cb30-5e68461f0387"
      },
      "source": [
        "#@title Running Webapp, click the URL below to open a new tab { display-mode: \"form\" }\n",
        "\n",
        "gr.Interface(\n",
        "  predictions_gradio, gr.inputs.Image(shape=(300, 300)), \"text\").launch()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on External URL: https://19363.gradio.app\n",
            "Interface loading below...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"1000\"\n",
              "            height=\"500\"\n",
              "            src=\"https://19363.gradio.app\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f8894385a20>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<gradio.networking.serve_files_in_background.<locals>.HTTPServer at 0x7f88f95b2b38>,\n",
              " 'http://127.0.0.1:7860/',\n",
              " 'https://19363.gradio.app')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    }
  ]
}